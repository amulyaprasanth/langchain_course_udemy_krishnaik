{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "568998bf",
   "metadata": {},
   "source": [
    "# Getting Started with Langchain and OpenAI\n",
    "\n",
    "In this quickstart, we'll see how to: \n",
    "* Get setup with Langchain, Langsmith and LangServe\n",
    "* Use the most basic and common components of LangChain: prompt templates, models and output parsers.\n",
    "* Build a simple application with LangChain\n",
    "* Trace your application with LangChain\n",
    "* Serve your application with LangServe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5574b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc37513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prasanth/projects/Langchain/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x7ed3c34d0620> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7ed3c3372570> root_client=<openai.OpenAI object at 0x7ed514130050> root_async_client=<openai.AsyncOpenAI object at 0x7ed3c3b855b0> model_name='gpt-4o-mini' model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31964f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Generative AI refers to a class of artificial intelligence models designed to generate new content based on the data they have been trained on. Unlike traditional AI models that might classify data or make predictions, generative AI creates novel outputs, which can include text, images, music, or any other type of media.\\n\\n**Key Features of Generative AI:**\\n\\n1. **Content Creation**: Generative AI can produce original content, such as writing articles (e.g., ChatGPT), generating realistic images (e.g., DALL-E, Midjourney), composing music, or even designing products.\\n\\n2. **Learning from Data**: These models typically use large datasets to learn patterns, structures, and the relationships within the data. For example, a generative text model would analyze numerous texts to learn grammar, context, style, and much more.\\n\\n3. **Types of Models**: Common architectures for generative AI include:\\n   - **Generative Adversarial Networks (GANs)**: These consist of two neural networks (a generator and a discriminator) that work against each other to improve the quality of generated content.\\n   - **Variational Autoencoders (VAEs)**: These models learn to encode data and then decode it back into forms that resemble the original data, enabling the generation of new samples.\\n   - **Transformers**: Models like GPT (Generative Pretrained Transformer) are based on this architecture and are particularly effective in generating coherent and contextually relevant text.\\n\\n4. **Applications**: Generative AI has a wide range of applications, including creative writing, artistic image generation, video game design, drug discovery, and even creating realistic simulations for training purposes.\\n\\n5. **Ethical Considerations**: The rise of generative AI also brings forth ethical concerns, such as the potential for misuse (deepfakes, misinformation), copyright issues, and biases embedded in generated content.\\n\\nOverall, generative AI represents a significant advancement in the field of artificial intelligence, enabling machines to create content that can mimic human creativity across various domains.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 414, 'prompt_tokens': 12, 'total_tokens': 426, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CIxSBMtvVm0pQSz6QrZ6kqm2ljyMQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8ab876ce-c3f6-44fa-9373-55b5762d347f-0' usage_metadata={'input_tokens': 12, 'output_tokens': 414, 'total_tokens': 426, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "## Input and get response from LLM\n",
    "result = llm.invoke(\"what is generative AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e99584",
   "metadata": {},
   "source": [
    "### Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b9a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answers based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are an expert AI Engineer. Provide me answers based on the question\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5febe8f4",
   "metadata": {},
   "source": [
    "## Chains \n",
    "\n",
    "Combining multiple components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51b5f1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Langsmith is a platform designed to assist developers and teams in building and deploying language-centric applications, particularly those that utilize large language models (LLMs). It focuses on providing tools and resources for managing prompts, iterating on models, and integrating various AI capabilities into applications. The platform aims to streamline the development process by offering features like version control for prompts, testing environments, and collaboration tools.\\n\\nLangsmith can help users improve their interactions with LLMs, ensuring that applications are more effective, efficient, and user-friendly. As of my last update in October 2023, more specific details about its offerings or features may vary, so it's advisable to check the official Langsmith website or other current resources for the most up-to-date information.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 148, 'prompt_tokens': 33, 'total_tokens': 181, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CIxVXFl3bKyLuUgUZkpWHCgsVQShm', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--1d3f1cda-2b3e-4fac-bea4-12b09a024b48-0' usage_metadata={'input_tokens': 33, 'output_tokens': 148, 'total_tokens': 181, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "response = chain.invoke({\"input\": \"can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b342011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04943d4e",
   "metadata": {},
   "source": [
    "## Output Parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ec805a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a framework designed to facilitate the development of applications powered by language models. It provides tools and components that help developers create applications that can interact with large language models (LLMs) in a more structured and effective manner. The framework supports various functionalities, including:\n",
      "\n",
      "1. **Chaining**: LangChain allows developers to create chains of actions and processes that can leverage multiple LLMs or integrate other data sources.\n",
      "\n",
      "2. **Memory**: It can maintain context or conversation history, enabling more coherent interactions in applications like chatbots.\n",
      "\n",
      "3. **Agents**: LangChain enables the creation of agents that can make decisions based on user input and external contexts, allowing for dynamic and responsive application behavior.\n",
      "\n",
      "4. **Integration**: The framework supports integration with other tools, APIs, and data sources, making it easier to build comprehensive and powerful applications.\n",
      "\n",
      "In essence, LangChain aims to simplify the process of building applications using LLMs, providing robust abstractions and utilities to manage complexity effectively.\n"
     ]
    }
   ],
   "source": [
    "## StrOutput Parser\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21000d57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
